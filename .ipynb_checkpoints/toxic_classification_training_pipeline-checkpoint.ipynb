{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27af4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def download_and_load_data():\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        \"192.168.1.10:30950\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    filename = \"toxic_comments.csv\"\n",
    "    try:\n",
    "        response = minio_client.get_object(minio_bucket, \"dataset/\"+filename)\n",
    "        # Read data from response.\n",
    "        response.close()\n",
    "        response.release_conn()\n",
    "    except:\n",
    "        url = \"https://raw.githubusercontent.com/agungfazrulhaq/toxicdetection/main/data/train.csv\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "\n",
    "        print(\"Downloaded file \"+filename)\n",
    "        minio_client.fput_object(minio_bucket, \"dataset/toxic_comments.csv\", \"toxic_comments.csv\")\n",
    "        print(\"Stored downloaded dataset\")\n",
    "\n",
    "def transform_and_split_train(split_size:float = 0.9) :\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        \"192.168.1.10:30950\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    filename = \"toxic_comments.csv\"\n",
    "    def remove_stopwords(sentence):\n",
    "        \"\"\"\n",
    "        Removes a list of stopwords\n",
    "\n",
    "        Args:\n",
    "            sentence (string): sentence to remove the stopwords from\n",
    "\n",
    "        Returns:\n",
    "            sentence (string): lowercase sentence without the stopwords\n",
    "        \"\"\"\n",
    "        # List of stopwords\n",
    "        stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "        # Sentence converted to lowercase-only\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        words = sentence.split()\n",
    "        no_words = [w for w in words if w not in stopwords]\n",
    "        sentence = \" \".join(no_words)\n",
    "\n",
    "        return sentence\n",
    "\n",
    "    def remove_symbols(sentence) :\n",
    "        return re.sub(r'[^\\w]', ' ', sentence)\n",
    "    \n",
    "    minio_client.fget_object(minio_object, \"dataset/toxic_comments.csv\", \"/tmp/toxic_comments.csv\")\n",
    "    df_train = pd.read_csv(\"toxic_comments.csv\")\n",
    "    train = df_train[['comment_text','toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "    \n",
    "    train[\"text_no_stopwords\"] = train[\"comment_text\"].apply(lambda x : remove_stopwords(x))\n",
    "    train[\"text_final\"] = train[\"text_no_stopwords\"].apply(lambda x : remove_symbols(x))\n",
    "    \n",
    "    def train_val_split(data, split) :\n",
    "        train = []\n",
    "        train_label = []\n",
    "        validation = []\n",
    "        val_label = []\n",
    "        for ind,val in data.iterrows() :\n",
    "            if len(train) < len(data)*split :\n",
    "                train.append(val['text_final'])\n",
    "                train_label.append(np.array(val[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].values))\n",
    "            else :\n",
    "                validation.append(val['text_final'])\n",
    "                val_label.append(np.array(val[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].values))\n",
    "\n",
    "        train = np.array(train)\n",
    "        train_label = np.array(train_label)\n",
    "        validation = np.array(validation)\n",
    "        val_label = np.array(val_label)\n",
    "\n",
    "        return train, train_label, validation, val_label\n",
    "    \n",
    "    x_train, y_train, x_val, y_val = train_val_split(train, split_size)\n",
    "    \n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    y_val = np.asarray(y_val).astype(np.float32)\n",
    "    \n",
    "    np.save(\"/tmp/x_train.npy\", x_train)\n",
    "    minio_client.fput_object(minio_object, \"commentoxic/x_train\", \"/tmp/x_train.npy\")\n",
    "    \n",
    "    np.save(\"/tmp/y_train.npy\", y_train)\n",
    "    minio_client.fput_object(minio_object, \"commentoxic/y_train\", \"/tmp/y_train.npy\")\n",
    "    \n",
    "    np.save(\"/tmp/x_val.npy\", x_val)\n",
    "    minio_client.fput_object(minio_object, \"commentoxic/x_val\", \"/tmp/x_val.npy\")\n",
    "    \n",
    "    np.save(\"/tmp/y_val.npy\", y_val)\n",
    "    minio_client.fput_object(minio_object, \"commentoxic/y_val\", \"/tmp/y_val.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce04617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
